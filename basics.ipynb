{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Re-implement [this](https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Architecture\n",
    "\n",
    "TensorFlow Core:\n",
    "1. Building the computational graph (a tf.Graph)\n",
    "2. Running the computational graph (using a tf.Session)\n",
    "\n",
    "Graphs are composed of:\n",
    "1. Operations (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors.\n",
    "2. Tensors: The edges in the graph. These represent the values that will flow through the graph. Most TensorFlow functions return tf.Tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "**Important: tf.Tensors do not have values, they are just handles to elements in the computation graph.**\n",
    "\n",
    "A tensor's rank is its number of dimensions, while its shape is a tuple of integers specifying the array's length along each dimension.  TensorFlow uses numpy arrays to represent tensor values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = tf.constant([1., 2., 3.])\n",
    "test2 = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "test3 = tf.constant([[[1., 2., 3.]], [[7., 8., 9.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, [3])\n",
      "(2, [2, 3])\n",
      "(3, [2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "def get_rank_shape(x):\n",
    "    return len(x.shape), x.shape.as_list()\n",
    "\n",
    "print(get_rank_shape(test1))\n",
    "print(get_rank_shape(test2))\n",
    "print(get_rank_shape(test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the computation graph has been built, you can run the computation that produces a particular tf.Tensor and fetch the value assigned to it. This is often useful for debugging as well as being required for much of TensorFlow to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 9]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    constant = tf.constant([1, 2, 3])\n",
    "    tensor = constant * constant\n",
    "    print(tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping tensors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_three_tensor = tf.ones([3, 4, 5])\n",
    "matrix = tf.reshape(rank_three_tensor, [6, 10])\n",
    "matrix.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions\n",
    "\n",
    "**If a tf.Graph is like a .py file, a tf.Session is like the python executable.**\n",
    "\n",
    "Notice that printing the tensors does not output the values 3.0, 4.0, and 7.0 as you might expect. The above statements only build the computation graph. These tf.Tensor objects just represent the results of the operations that will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_5:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.float32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)\n",
    "\n",
    "sess.run(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During a call to tf.Session.run any tf.Tensor only has a single value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7046287  0.7383052  0.64732885]\n",
      "[0.77279234 0.33991587 0.05429554]\n",
      "(array([1.4811295, 1.2722859, 1.157337 ], dtype=float32), array([2.4811296, 2.272286 , 2.157337 ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding\n",
    "\n",
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later, like a function argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "z = x + y\n",
    "\n",
    "print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "print(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "To get a runnable tf.Tensor from a Dataset you must first convert it to a tf.data.Iterator, and then call the Iterator's get_next method.  The simplest way to create an Iterator is with the make_one_shot_iterator method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[2 3]\n",
      "[4 5]\n",
      "[6 7]\n"
     ]
    }
   ],
   "source": [
    "my_data = [\n",
    "    [0, 1,],\n",
    "    [2, 3,],\n",
    "    [4, 5,],\n",
    "    [6, 7,],\n",
    "]\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "next_item = slices.make_one_shot_iterator().get_next()\n",
    "\n",
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_item))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some TensorFlow functions return tf.Operations instead of tf.Tensors. The result of calling run on an Operation is None. You run an operation to cause a side-effect, not to retrieve a value. Examples of this include the initialization, and training ops demonstrated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3845165  0.4968612 -0.5291756]\n",
      "[-0.9508269  1.6286633 -0.5802473]\n",
      "[ 0.19768722 -1.2751924  -0.7901949 ]\n",
      "[-0.35618597 -0.66406137 -2.3090224 ]\n",
      "[1.7756457 0.5720449 1.1697505]\n",
      "[-1.3467379  -0.46261194 -1.0825694 ]\n",
      "[ 1.1338474 -0.7046132  0.8558197]\n",
      "[-0.40513965  0.24549866  1.2865839 ]\n",
      "[0.55418175 1.2342918  1.8840885 ]\n",
      "[-1.384604    0.804429    0.60902476]\n"
     ]
    }
   ],
   "source": [
    "r = tf.random_normal([10,3])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "sess.run(iterator.initializer)\n",
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_row))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "A trainable model must modify the values in the graph to get new outputs with the same input. Layers are the preferred way to add trainable parameters to a graph.\n",
    "\n",
    "Layers package together both the variables and the operations that act on them. For example a dense (or fully-connected) layer performs a weighted sum across all inputs for each output and applies an optional activation function. The connection weights and biases are managed by the layer object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a Dense layer that takes a batch of input vectors, and produces a single output value for each. To apply a layer to an input, call the layer as if it were a function.  The layer inspects its input to determine sizes for its internal variables. So here we must set the shape of the x placeholder so that the layer can build a weight matrix of the correct size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer dense_1 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f548642834d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, shape=[None, 3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlinear_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/tensor-flow-first-steps/venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tensor-flow-first-steps/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tensor-flow-first-steps/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m           raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0;32m-> 1412\u001b[0;31m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                            \u001b[0;34m'its rank is undefined, but the layer requires a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                            'defined rank.')\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer dense_1 is incompatible with the layer: its rank is undefined, but the layer requires a defined rank."
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)#, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1, kernel_initializer=tf.zeros_initializer, bias_initializer=tf.constant_initializer(1))\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1, kernel_initializer=tf.constant_initializer([1, 2, 3]), \n",
    "                               bias_initializer=tf.constant_initializer(1))\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer contains variables that must be initialized before they can be used. \n",
    "\n",
    "A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.  Variables are manipulated via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Unlike tf.Tensor objects, a tf.Variable exists outside the context of a single session.run call.\n",
    "\n",
    "**Important: Calling tf.global_variables_initializer only creates and returns a handle to a TensorFlow operation. That op will initialize all the global variables when we run it with tf.Session.run.**\n",
    "\n",
    "**Also note that this global_variables_initializer only initializes variables that existed in the graph when the initializer was created. So the initializer should be one of the last things added during graph construction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.],\n",
       "        [2.],\n",
       "        [3.]], dtype=float32), array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(linear_model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.],\n",
       "       [33.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns\n",
    "\n",
    "The easiest way to experiment with feature columns is using the tf.feature_column.input_layer function. This function only accepts dense columns as inputs, so to view the result of a categorical column you must wrap it in an tf.feature_column.indicator_column.\n",
    "\n",
    "Definition of dense column??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'sales' : [[5], [10], [8], [9]],\n",
    "    'department': ['sports', 'sports', 'gardening', 'gardening']\n",
    "}\n",
    "\n",
    "department_column = tf.feature_column.categorical_column_with_vocabulary_list('department', ['sports', 'gardening'])\n",
    "department_column = tf.feature_column.indicator_column(department_column)\n",
    "\n",
    "columns = [\n",
    "    tf.feature_column.numeric_column('sales'),\n",
    "    department_column\n",
    "]\n",
    "\n",
    "inputs = tf.feature_column.input_layer(features, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature columns can have internal state, like layers, so they often need to be initialized. Categorical columns use lookup tables internally and these require a separate initialization op, tf.tables_initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  5.],\n",
       "       [ 1.,  0., 10.],\n",
       "       [ 0.,  1.,  8.],\n",
       "       [ 0.,  1.,  9.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "table_init = tf.tables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run((var_init, table_init))\n",
    "sess.run(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together\n",
    "\n",
    "A simple linear regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "1.69\n",
      "0.87035024\n",
      "0.4957618\n",
      "0.3213858\n",
      "0.23726682\n",
      "0.19401541\n",
      "0.16943617\n",
      "0.15354478\n",
      "0.14184044\n",
      "0.13228557\n",
      "0.123949364\n",
      "0.11639896\n",
      "0.10942595\n",
      "0.102923475\n",
      "0.0968312\n",
      "0.0911102\n",
      "0.08573199\n",
      "0.08067339\n",
      "0.07591425\n",
      "0.0714363\n",
      "0.06722271\n",
      "0.063257694\n",
      "0.059526626\n",
      "0.056015614\n",
      "0.052711725\n",
      "0.04960269\n",
      "0.046677034\n",
      "0.04392396\n",
      "0.041333247\n",
      "0.03889534\n",
      "0.036601223\n",
      "0.03444241\n",
      "0.032410946\n",
      "0.030499289\n",
      "0.028700395\n",
      "0.027007595\n",
      "0.025414642\n",
      "0.02391563\n",
      "0.022505064\n",
      "0.021177668\n",
      "0.019928578\n",
      "0.018753154\n",
      "0.017647067\n",
      "0.016606199\n",
      "0.015626743\n",
      "0.014705041\n",
      "0.013837724\n",
      "0.013021546\n",
      "0.012253509\n",
      "0.011530784\n",
      "0.0108506745\n",
      "0.010210691\n",
      "0.009608445\n",
      "0.0090417275\n",
      "0.008508431\n",
      "0.008006589\n",
      "0.0075343386\n",
      "0.0070899576\n",
      "0.006671782\n",
      "0.006278269\n",
      "0.005907961\n",
      "0.0055595017\n",
      "0.0052315886\n",
      "0.004923025\n",
      "0.0046326537\n",
      "0.0043594074\n",
      "0.0041022855\n",
      "0.0038603302\n",
      "0.0036326402\n",
      "0.0034183827\n",
      "0.0032167563\n",
      "0.0030270237\n",
      "0.002848486\n",
      "0.0026804795\n",
      "0.0025223778\n",
      "0.002373601\n",
      "0.0022336063\n",
      "0.0021018598\n",
      "0.0019778912\n",
      "0.0018612323\n",
      "0.0017514552\n",
      "0.0016481485\n",
      "0.0015509406\n",
      "0.0014594619\n",
      "0.0013733795\n",
      "0.0012923757\n",
      "0.0012161508\n",
      "0.0011444166\n",
      "0.0010769179\n",
      "0.0010134013\n",
      "0.00095362565\n",
      "0.0008973813\n",
      "0.0008444521\n",
      "0.0007946431\n",
      "0.0007477753\n",
      "0.00070367166\n",
      "0.0006621649\n",
      "0.0006231119\n",
      "0.0005863573\n",
      "[[-0.03792882]\n",
      " [-1.018379  ]\n",
      " [-1.9988294 ]\n",
      " [-2.9792795 ]]\n",
      "[array([[-0.9804502]], dtype=float32), array([0.9425214], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "data = {\n",
    "    x: [[1], [2], [3], [4]],\n",
    "    y_true: [[0], [-1], [-2], [-3]]\n",
    "}\n",
    "\n",
    "linear_model = tf.layers.Dense(units=1,\n",
    "                               kernel_initializer=tf.zeros_initializer, \n",
    "                               bias_initializer=tf.zeros_initializer)\n",
    "\n",
    "y_pred = linear_model(x)\n",
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(100):\n",
    "  _, loss_value = sess.run((train, loss), feed_dict=data)\n",
    "  print(loss_value)\n",
    "\n",
    "print(sess.run(y_pred, feed_dict=data))\n",
    "print(sess.run(linear_model.weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
